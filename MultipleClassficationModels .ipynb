{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2968f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Implementation \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import defaultdict\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Read Data-\n",
    "data = pd.read_csv('DataLocation...', delimiter=';')\n",
    "\n",
    "flow_regimes = ['Data1', 'Data2', 'Data3']\n",
    "df = {}\n",
    "x_values = {}\n",
    "y_values = {}\n",
    "\n",
    "for regime in flow_regimes:\n",
    "    df[regime] = data[(data['O1'] == 'Data' ) & (data['O2'] == regime)]\n",
    "    df[regime] = df[regime][['R1', 'R2']]\n",
    "    \n",
    "    #Log Data if Needed\n",
    "    df[regime] = np.log(df[regime][['R1', 'R2']])\n",
    "    \n",
    "    x_values[regime] = df[regime]['R1']\n",
    "    y_values[regime] = df[regime]['R2']\n",
    "    \n",
    "features = pd.DataFrame(columns=['R1', 'R2'])\n",
    "labels = pd.Series()\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Get the regimes \n",
    "for regime in flow_regimes:\n",
    "    features = pd.concat([features, df[regime]], ignore_index=True)\n",
    "    labels = pd.concat([labels, pd.Series([regime] * len(df[regime]))], ignore_index=True)\n",
    "    \n",
    "#Visualize the data\n",
    "class_counts = labels.value_counts()\n",
    "print(\"Class Distribution:\")\n",
    "print(class_counts)\n",
    "\n",
    "plt.bar(class_counts.index, class_counts.values)\n",
    "plt.xlabel(\"Flow Regime\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()  \n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Maintain Randomness by iterating on random states and Performing KNN  \n",
    "top_results = defaultdict(float)\n",
    "best_k_values = []\n",
    "average_accuracy = 0\n",
    "\n",
    "random_states = random.sample(range(1, 100), 50)\n",
    "k_values = list(range(1, 100))\n",
    "\n",
    "for random_state in random_states:\n",
    "    # Split the data into training, validation, and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=random_state)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=random_state)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "    k_folds = 5  # Number of folds for cross-validation\n",
    "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Initialize lists to store shuffled data\n",
    "    X_train_shuffled, y_train_shuffled = [], []\n",
    "\n",
    "    # Perform cross-validation shuffle\n",
    "    for train_index, _ in skf.split(X_train, y_train):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_train_shuffled.append(X_train_fold)\n",
    "        y_train_shuffled.append(y_train_fold)\n",
    "\n",
    "    # Convert shuffled lists to DataFrames/Series\n",
    "    X_train_shuffled = pd.concat(X_train_shuffled, ignore_index=True)\n",
    "    y_train_shuffled = pd.concat(y_train_shuffled, ignore_index=True)\n",
    "\n",
    "    # Resample the training data using SMOTE\n",
    "    ros = SMOTE(random_state=random_state)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train_shuffled, y_train_shuffled)\n",
    "\n",
    "    # Get the Best Value of k\n",
    "    acc = []\n",
    "    for k in k_values:\n",
    "        if k <= len(X_train_resampled):\n",
    "            knn = KNeighborsClassifier(n_neighbors=k).fit(X_train_resampled, y_train_resampled)\n",
    "            y_pred = knn.predict(X_val)\n",
    "            acc.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "    best_k = acc.index(max(acc)) + 1\n",
    "    best_k_values.append(best_k)\n",
    "\n",
    "    # Train a KNN classifier with the best K\n",
    "    knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    knn.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    average_accuracy += accuracy\n",
    "\n",
    "    # Store the result in the dictionary\n",
    "    top_results[random_state] = accuracy\n",
    "\n",
    "# Calculate the average accuracy\n",
    "average_accuracy /= len(random_states)\n",
    "\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Visualizing the results\n",
    "# Define color mappings for each flow regime\n",
    "color_map = {'data colors....'}\n",
    "X_test['Predicted'] = y_pred\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "font = FontProperties(family='Times New Roman', size=12)\n",
    "\n",
    "# Plot the KNN model results in the first subplot\n",
    "ax1 = axes[0]\n",
    "ax1.set_title('Test Data Scatter Plot', fontproperties=font)\n",
    "ax1.set_xlabel('R1', fontproperties=font)\n",
    "ax1.set_ylabel('R2', fontproperties=font)\n",
    "\n",
    "for regime in flow_regimes:\n",
    "    ax1.scatter(X_test[X_test['Predicted'] == regime]['R1'], X_test[X_test['Predicted'] == regime]['R2'],\n",
    "                color=color_map[regime], label=regime)\n",
    "\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot the actual data in the second subplot\n",
    "ax2 = axes[1]\n",
    "ax2.set_title('Actual Data Scatter Plot', fontproperties=font)\n",
    "ax2.set_xlabel('R1', fontproperties=font)\n",
    "ax2.set_ylabel('R2', fontproperties=font)\n",
    "\n",
    "for regime in flow_regimes:\n",
    "    ax2.scatter(x_values[regime], y_values[regime], s=10, color=color_map[regime])\n",
    "\n",
    "# Create a combined legend for both subplots\n",
    "labels = list(color_map.keys())\n",
    "scatter_plots = [ax2.scatter([], [], s=10, color=color_map[label]) for label in labels]\n",
    "legend_elements = ax2.legend(scatter_plots, labels, loc='upper right', title='Flow Regimes')\n",
    "ax2.add_artist(legend_elements)\n",
    "\n",
    "ax2.grid(True)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d035ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Implementation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Read Data-\n",
    "data = pd.read_csv('DataLocation...', delimiter=';')\n",
    "\n",
    "flow_regimes = ['Data1', 'Data2', 'Data3']\n",
    "df = {}\n",
    "x_values = {}\n",
    "y_values = {}\n",
    "\n",
    "for regime in flow_regimes:\n",
    "    df[regime] = data[(data['O1'] == 'Data' ) & (data['O2'] == regime)]\n",
    "    df[regime] = df[regime][['R1', 'R2']]\n",
    "    \n",
    "    #Log Data if Needed\n",
    "    df[regime] = np.log(df[regime][['R1', 'R2']])\n",
    "    \n",
    "    x_values[regime] = df[regime]['R1']\n",
    "    y_values[regime] = df[regime]['R2']\n",
    "\n",
    "features = pd.DataFrame(columns=['R1', 'R2'])\n",
    "labels = pd.Series()\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Get the regimes \n",
    "for regime in flow_regimes:\n",
    "    features = pd.concat([features, df[regime]], ignore_index=True)\n",
    "    labels = pd.concat([labels, pd.Series([regime] * len(df[regime]))], ignore_index=True)\n",
    "    \n",
    "class_counts = labels.value_counts()\n",
    "print(\"Class Distribution:\")\n",
    "print(class_counts)\n",
    "\n",
    "plt.bar(class_counts.index, class_counts.values)\n",
    "plt.xlabel(\"Flow Regime\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Maintain Randomness by iterating on random states and Performing Naive Bayes \n",
    "top_results = defaultdict(float)\n",
    "accuracy_sum = 0.0\n",
    "precision_sum = defaultdict(float)\n",
    "recall_sum = defaultdict(float)\n",
    "f1_score_sum = defaultdict(float)\n",
    "\n",
    "# Generate 100 random states\n",
    "random_states = random.sample(range(1, 2000), 100)\n",
    "\n",
    "for random_state in random_states:\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=random_state)\n",
    "\n",
    "    k_folds = 5  # Number of folds for cross-validation\n",
    "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Initialize lists to store shuffled data\n",
    "    X_train_shuffled, y_train_shuffled = [], []\n",
    "\n",
    "    # Perform cross-validation shuffle\n",
    "    for train_index, _ in skf.split(X_train, y_train):\n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        X_train_shuffled.append(X_train_fold)\n",
    "        y_train_shuffled.append(y_train_fold)\n",
    "\n",
    "    # Convert shuffled lists to DataFrames/Series\n",
    "    X_train_shuffled = pd.concat(X_train_shuffled, ignore_index=True)\n",
    "    y_train_shuffled = pd.concat(y_train_shuffled, ignore_index=True)\n",
    "\n",
    "    # Resample the training data using SMOTE\n",
    "    ros = SMOTE(random_state=random_state)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X_train_shuffled, y_train_shuffled)\n",
    "\n",
    "    # Train a Naive Bayes classifier\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Store the result in the dictionary\n",
    "    top_results[random_state] = accuracy\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Add precision, recall, and F1-score to the sum\n",
    "    for label in flow_regimes:\n",
    "        precision_sum[label] += report[label]['precision']\n",
    "        recall_sum[label] += report[label]['recall']\n",
    "        f1_score_sum[label] += report[label]['f1-score']\n",
    "\n",
    "    # Add accuracy to the sum\n",
    "    accuracy_sum += accuracy\n",
    "         \n",
    "# Print the resampled data shape\n",
    "print(\"Resampled Training Data Shape:\", X_train_resampled.shape)\n",
    "\n",
    "# Check the class distribution after resampling\n",
    "resampled_class_counts = pd.Series(y_train_resampled).value_counts()\n",
    "print(\"Class Distribution after Resampling:\")\n",
    "print(resampled_class_counts)\n",
    "\n",
    "# Calculate average precision, recall, and F1-score\n",
    "average_precision = {label: precision_sum[label] / len(random_states) for label in flow_regimes}\n",
    "average_recall = {label: recall_sum[label] / len(random_states) for label in flow_regimes}\n",
    "average_f1_score = {label: f1_score_sum[label] / len(random_states) for label in flow_regimes}\n",
    "\n",
    "# Calculate average accuracy\n",
    "average_accuracy = accuracy_sum / len(random_states)\n",
    "\n",
    "# Print the average accuracy, precision, recall, and F1-score\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Visualizing the results\n",
    "# Plot bar chart\n",
    "x = range(len(flow_regimes))\n",
    "width = 0.2\n",
    "\n",
    "plt.bar(x, average_precision.values(), width, label='Precision')\n",
    "plt.bar([i + width for i in x], average_recall.values(), width, label='Recall')\n",
    "plt.bar([i + (2 * width) for i in x], average_f1_score.values(), width, label='F1-Score')\n",
    "\n",
    "plt.xlabel('Flow Regime')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Average Classification Report')\n",
    "plt.xticks([i + width for i in x], flow_regimes)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd226c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means Clustering Implementation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Read Data-\n",
    "data = pd.read_csv('DataLocation...', delimiter=';')\n",
    "\n",
    "flow_regimes = ['Data1', 'Data2', 'Data3']\n",
    "df = {}\n",
    "x_values = {}\n",
    "y_values = {}\n",
    "\n",
    "for regime in flow_regimes:\n",
    "    df[regime] = data[(data['O1'] == 'Data' ) & (data['O2'] == regime)]\n",
    "    df[regime] = df[regime][['R1', 'R2']]\n",
    "    \n",
    "    #Log Data if Needed\n",
    "    df[regime] = np.log(df[regime][['R1', 'R2']])\n",
    "    \n",
    "    x_values[regime] = df[regime]['R1']\n",
    "    y_values[regime] = df[regime]['R2']\n",
    "\n",
    "features = pd.DataFrame(columns=['R1', 'R2'])\n",
    "labels = pd.Series()\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Get the regimes \n",
    "for regime in flow_regimes:\n",
    "    features = pd.concat([features, df[regime]], ignore_index=True)\n",
    "    labels = pd.concat([labels, pd.Series([regime] * len(df[regime]))], ignore_index=True)\n",
    "    \n",
    "class_counts = labels.value_counts()\n",
    "print(\"Class Distribution:\")\n",
    "print(class_counts)\n",
    "\n",
    "plt.bar(class_counts.index, class_counts.values)\n",
    "plt.xlabel(\"Flow Regime\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Performing K-means \n",
    "# Split the data into 70% training and 30% testing\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "# Train the K-means clustering model on the standardized training set\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(train_features_scaled)\n",
    "\n",
    "# Predict the clusters for the training set and test set\n",
    "train_predictions = kmeans.predict(train_features_scaled)\n",
    "test_predictions = kmeans.predict(test_features_scaled)\n",
    "\n",
    "# Define the desired colors for each flow regime\n",
    "colors = {\n",
    "    'D1': 'orange',\n",
    "    'D2 ': 'red',\n",
    "    'D3': 'blue',\n",
    "    'D4': 'green'\n",
    "}\n",
    "\n",
    "# Define the cluster labels\n",
    "cluster_labels = {\n",
    "    0: 'D1 Cluster',\n",
    "    1: 'D2 Cluster',\n",
    "    2: 'D3 Cluster',\n",
    "    3: 'D4 Cluster'\n",
    "}\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_silhouette = silhouette_score(test_features_scaled, test_predictions)\n",
    "print(f\"Silhouette Coefficient on the test set: {test_silhouette}\")\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Visualizing the results\n",
    "# Add custom legend\n",
    "custom_legend = [\n",
    "    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='orange', markersize=10),\n",
    "    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10),\n",
    "    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10),\n",
    "    plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='green', markersize=10),\n",
    "]\n",
    "\n",
    "legend_labels = ['D1', 'D2', 'D3', 'D4']\n",
    "\n",
    "# Actual Data with Cluster Labels\n",
    "plt.figure(figsize=(15, 6))  # Increase the figure width\n",
    "plt.subplot(1, 2, 1)\n",
    "for i in range(k):\n",
    "    regime_label = cluster_labels[i].split()[0]  # Extract the flow regime label\n",
    "    plt.scatter(train_features.loc[train_predictions == i, 'R1'], train_features.loc[train_predictions == i, 'R2'])\n",
    "\n",
    "plt.title('Train Data with Cluster Labels')\n",
    "plt.xlabel('Gas Superficial Velocity (mps)')\n",
    "plt.ylabel('Liquid Superficial Velocity (mps)')\n",
    "plt.legend(custom_legend, legend_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test Set with Predicted Cluster Labels\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in range(k):\n",
    "    regime_label = cluster_labels[i].split()[0]  # Extract the flow regime label\n",
    "    plt.scatter(test_features.loc[test_predictions == i, 'R1'], test_features.loc[test_predictions == i, 'R2'])\n",
    "plt.scatter(\n",
    "    scaler.inverse_transform(kmeans.cluster_centers_)[:, 0],\n",
    "    scaler.inverse_transform(kmeans.cluster_centers_)[:, 1],\n",
    "    c='red', marker='*', s=100, label='Cluster Centers'\n",
    ")\n",
    "plt.title('Test Set with Predicted Cluster Labels')\n",
    "plt.xlabel('Gas Superficial Velocity (mps)')\n",
    "plt.ylabel('Liquid Superficial Velocity (mps)')\n",
    "plt.legend(custom_legend, legend_labels)\n",
    "\n",
    "\n",
    "# Test Set with Predicted Cluster Labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a color palette for the clusters\n",
    "palette = sns.color_palette('bright', 4)\n",
    "legend_labels = ['D1', 'D2', 'D3', 'D4']\n",
    "# Plot the scatter points for each cluster with colored areas\n",
    "for i in range(k):\n",
    "    cluster_points = test_features[test_predictions == i]\n",
    "    plt.scatter(\n",
    "        cluster_points['R1'],\n",
    "        cluster_points['R2'],\n",
    "        color=palette[i],\n",
    "        label=f'{legend_labels[i]}'\n",
    "    )\n",
    "    sns.kdeplot(\n",
    "        data=cluster_points,\n",
    "        x='R1',\n",
    "        y='R2',\n",
    "        shade=True,\n",
    "        color=palette[i],\n",
    "        alpha=0.6\n",
    "    )\n",
    "\n",
    "# Plot the cluster centers as stars\n",
    "plt.scatter(\n",
    "    scaler.inverse_transform(kmeans.cluster_centers_)[:, 0],\n",
    "    scaler.inverse_transform(kmeans.cluster_centers_)[:, 1],\n",
    "    c='red', marker='*', s=50, label='Cluster Centers'\n",
    ")\n",
    "\n",
    "plt.title('Test Set with Predicted Cluster Labels')\n",
    "plt.xlabel('Gas Superficial Velocity (mps)')\n",
    "plt.ylabel('Liquid Superficial Velocity (mps)')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4792b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATBOOST & XGBOOST Implementation \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the dataset from CSV file\n",
    "data = pd.read_csv('DataLocation...', delimiter=';')\n",
    "\n",
    "# Map class labels to numeric values\n",
    "label_map = {'Case': 0, 'Control': 1}\n",
    "data['Label'] = data['Label'].map(label_map)\n",
    "\n",
    "# Extract the feature variables (X) and target variable (y)\n",
    "x_values = data.iloc[:, 1:].values  # Use all columns except the first one as features\n",
    "y_values = data.iloc[:, 0].values  # Use the first column as the target variable\n",
    "\n",
    "# Normalize the feature variables\n",
    "scaler = StandardScaler()\n",
    "x_values = scaler.fit_transform(x_values)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_values, y_values, test_size=0.2, random_state=34)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training set shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", x_test.shape, y_test.shape)\n",
    "\n",
    "# Create an CatBoost classifier\n",
    "model = CatBoostClassifier()\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Perform 5-fold cross-validation on the training set\n",
    "scores = cross_val_score(model, x_train, y_train, cv=5)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Mean Score:\", np.mean(scores))\n",
    "\n",
    "# Train the classifier\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = recall_score(y_test, y_pred)\n",
    "print(\"Sensitivity (Recall):\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "print(\"Specificity:\", specificity)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate MCC\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print(\"MCC:\", mcc)\n",
    "\n",
    "# Calculate f1-score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
